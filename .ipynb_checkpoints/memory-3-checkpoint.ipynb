{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "Expected ident at file:///repl.tsx:7:1\n\n  const memory = new BufferMemory()\n  ~~~~~",
     "evalue": "Expected ident at file:///repl.tsx:7:1\n\n  const memory = new BufferMemory()\n  ~~~~~",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "import { Ollama } from \"@langchain/community/llms/ollama\";\n",
    "import { BufferMemory } from \"langchain/memory\";\n",
    "import { RunnableSequence } from \"@langchain/core/runnables\"\n",
    "import { RunnablePassthrough } from \"@langchain/core/runnables\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\"\n",
    "const model = new Ollama({ model: \"llama3\", baseUrl: \"http://localhost:11434\", verbose: true }),\n",
    "const memory = new BufferMemory();\n",
    "\n",
    "const TEMPLATE = `\n",
    "你是一个乐于助人的 ai 助手。尽你所能回答所有问题。\n",
    "\n",
    "这是跟人类沟通的聊天历史:\n",
    "{history}\n",
    "\n",
    "据此回答人类的问题:\n",
    "{input}\n",
    "`\n",
    "const prompt = ChatPromptTemplate.fromTemplate(TEMPLATE)\n",
    "\n",
    "let template = \"\"\n",
    "const chain = RunnableSequence.from([\n",
    "    {\n",
    "        input: new RunnablePassthrough(),\n",
    "        memoryObject: async(input) => {\n",
    "            const history = await memory.loadMemoryVariables({\n",
    "                input\n",
    "            })\n",
    "            tempInput = input\n",
    "            return history\n",
    "        }\n",
    "    },\n",
    "    RunnablePassthrough.assign({\n",
    "        history: (input) => input.memoryObject.history\n",
    "    }),\n",
    "    prompt,\n",
    "    chatModel,\n",
    "    new StringOutputParser(),\n",
    "    new RunnablePassthrough({\n",
    "        func: async (output) => {\n",
    "            await memory.saveContext({\n",
    "                input: tempInput\n",
    "            }, {\n",
    "                output\n",
    "            })\n",
    "        }\n",
    "    })\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to read chat history from chat_data/test.json SyntaxError: Unexpected end of JSON input\n",
      "    at JSON.parse (<anonymous>)\n",
      "    at JSONChatHistory.getMessages (file:///Users/yyl/Documents/yyl/study/yyl-ai/jupyter-ai/js/JSONChatHistory/index.ts:37:35)\n",
      "    at JSONChatHistory.addMessages (file:///Users/yyl/Documents/yyl/study/yyl-ai/jupyter-ai/js/JSONChatHistory/index.ts:52:41)\n",
      "    at <anonymous>:7:15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\n",
       "  HumanMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"Hi, I'm yyl.\"\u001b[39m,\n",
       "      additional_kwargs: {},\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"Hi, I'm yyl.\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {},\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: { content: \u001b[32m\"hello\"\u001b[39m, additional_kwargs: {}, response_metadata: {} },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"hello\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {},\n",
       "    response_metadata: {}\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { JSONChatHistory } from \"./JSONChatHistory/index.ts\"\n",
    "import { AIMessage, HumanMessage } from \"@langchain/core/messages\";\n",
    "const history = new JSONChatHistory({\n",
    "    dir: \"chat_data\",\n",
    "    sessionId: \"test\"\n",
    "})\n",
    "\n",
    "await history.addMessages([\n",
    "    new HumanMessage(\"Hi, I'm yyl.\"),\n",
    "    new AIMessage(\"hello\"),\n",
    "])\n",
    "\n",
    "const messages = await history.getMessages()\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  response: \u001b[32m'My friend yyl! According to our database, your username is indeed \"yyl\". As I mentioned earlier, thi'\u001b[39m... 180 more characters\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { Ollama } from \"@langchain/community/llms/ollama\";\n",
    "import { BufferMemory } from \"langchain/memory\";\n",
    "import { ConversationChain } from \"langchain/chains\";\n",
    "\n",
    "const chatModel = new Ollama({ model: \"llama3\", baseUrl: \"http://localhost:11434\" });\n",
    "const memory = new BufferMemory({\n",
    "    chatHistory: history\n",
    "})\n",
    "const chain = new ConversationChain({llm: chatModel, memory: memory})\n",
    "const res1 = await chain.call({input: \"What is my name?\"})\n",
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  HumanMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"Hi, I'm yyl.\"\u001b[39m,\n",
       "      additional_kwargs: {},\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"Hi, I'm yyl.\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {},\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: { content: \u001b[32m\"hello\"\u001b[39m, additional_kwargs: {}, response_metadata: {} },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"hello\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {},\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  HumanMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"What is my name?\"\u001b[39m,\n",
       "      additional_kwargs: {},\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"What is my name?\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {},\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m'According to our database, your username is \"yyl\". This information was provided when you logged in '\u001b[39m... 278 more characters,\n",
       "      additional_kwargs: {},\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m'According to our database, your username is \"yyl\". This information was provided when you logged in '\u001b[39m... 278 more characters,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {},\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  HumanMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"What is my name?\"\u001b[39m,\n",
       "      additional_kwargs: {},\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"What is my name?\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {},\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m'My friend yyl! According to our database, your username is indeed \"yyl\". As I mentioned earlier, thi'\u001b[39m... 180 more characters,\n",
       "      additional_kwargs: {},\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m'My friend yyl! According to our database, your username is indeed \"yyl\". As I mentioned earlier, thi'\u001b[39m... 180 more characters,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {},\n",
       "    response_metadata: {}\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const message = await history.getMessages()\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
