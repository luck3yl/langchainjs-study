{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot read properties of undefined (reading 'additional_kwargs')",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "TypeError: Cannot read properties of undefined (reading 'additional_kwargs')",
      "    at JsonOutputToolsParser.parseResult (file:///Users/yyl/Library/Caches/deno/npm/registry.npmjs.org/@langchain/core/0.1.48/dist/output_parsers/openai_tools/json_output_tools_parsers.js:38:50)",
      "    at JsonOutputToolsParser._callWithConfig (file:///Users/yyl/Library/Caches/deno/npm/registry.npmjs.org/@langchain/core/0.1.48/dist/output_parsers/base.js:39:72)",
      "    at JsonOutputToolsParser._callWithConfig (file:///Users/yyl/Library/Caches/deno/npm/registry.npmjs.org/@langchain/core/0.1.48/dist/runnables/base.js:187:33)",
      "    at eventLoopTick (ext:core/01_core.js:168:7)",
      "    at async RunnableSequence.invoke (file:///Users/yyl/Library/Caches/deno/npm/registry.npmjs.org/@langchain/core/0.1.48/dist/runnables/base.js:1035:33)",
      "    at async <anonymous>:57:1"
     ]
    }
   ],
   "source": [
    "import { zodToJsonSchema } from \"zod-to-json-schema\";\n",
    "import { z } from \"zod\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\"\n",
    "import { Ollama } from \"@langchain/community/llms/ollama\";\n",
    "import { JsonOutputToolsParser } from \"@langchain/core/output_parsers/openai_tools\"\n",
    "import { RunnableSequence, RunnableBranch, RunnablePassthrough } from \"@langchain/core/runnables\"\n",
    "import { ChatPromptTemplate, PromptTemplate } from \"@langchain/core/prompts\"\n",
    "const classifySchema = z.object({\n",
    "    type: z.enum([\"ç§‘æ™®\", \"ç¼–ç¨‹\", \"ä¸€èˆ¬é—®é¢˜\"]).describe(\"ç”¨æˆ·æé—®çš„åˆ†ç±»\")\n",
    "})\n",
    "\n",
    "const model = new ChatOpenAI({\n",
    "    configuration: {\n",
    "            baseURL: \"https://api.aigc369.com/v1\",\n",
    "        },\n",
    "    temperature: 0 \n",
    "})\n",
    "\n",
    "const modelWithTools = model.bind({\n",
    "    tools: [\n",
    "        {\n",
    "            type: \"function\",\n",
    "            function: {\n",
    "                name: \"classifyQuestion\",\n",
    "                description: \"å¯¹ç”¨æˆ·çš„æé—®è¿›è¡Œåˆ†ç±»\",\n",
    "                parameters: zodToJsonSchema(classifySchema),\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    tool_choice: {\n",
    "        type: \"function\",\n",
    "        function: {\n",
    "           name: \"classifyQuestion\"\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "const prompt = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", `ä»”ç»†æ€è€ƒï¼Œä½ æœ‰å……è¶³çš„æ—¶é—´è¿›è¡Œä¸¥è°¨çš„æ€è€ƒï¼Œç„¶åŽå¯¹ç”¨æˆ·çš„é—®é¢˜è¿›è¡Œåˆ†ç±»ï¼Œ\n",
    "    å½“ä½ æ— æ³•åˆ†ç±»åˆ°ç‰¹å®šåˆ†ç±»æ—¶ï¼Œå¯ä»¥åˆ†ç±»åˆ° \"ä¸€èˆ¬é—®é¢˜\"`],\n",
    "    [\"human\", \"{input}\"]\n",
    "])\n",
    "\n",
    "const classifyChain = RunnableSequence.from([\n",
    "    prompt,\n",
    "    modelWithTools,\n",
    "    new JsonOutputToolsParser(),\n",
    "    (input) => {\n",
    "        const type = input[0]?.args?.type\n",
    "        return type ? type : \"ä¸€èˆ¬é—®é¢˜\"\n",
    "    }\n",
    "])\n",
    "\n",
    "await classifyChain.invoke({\n",
    "    \"input\": \"é²¸é±¼æ˜¯å“ºä¹³åŠ¨ç‰©ä¹ˆï¼Ÿ\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "const answeringModel = new Ollama({\n",
    "    baseUrl: \"http://localhost:11434\", \n",
    "    model: \"llama3\", \n",
    "    temperature: 0.7\n",
    "})\n",
    "const sciencePrompt = PromptTemplate.fromTemplate(\n",
    "    `ä½œä¸ºä¸€ä½ç§‘æ™®ä¸“å®¶ï¼Œä½ éœ€è¦è§£ç­”ä»¥ä¸‹é—®é¢˜ï¼Œå°½å¯èƒ½æä¾›è¯¦ç»†ã€å‡†ç¡®å’Œæ˜“äºŽç†è§£çš„ç­”æ¡ˆï¼š\n",
    "    é—®é¢˜ï¼š{input}\n",
    "    ç­”æ¡ˆï¼š`\n",
    ")\n",
    "const programmingPrompt = PromptTemplate.fromTemplate(\n",
    "    `ä½œä¸ºä¸€ä½ç¼–ç¨‹ä¸“å®¶ï¼Œä½ éœ€è¦è§£ç­”ä»¥ä¸‹ç¼–ç¨‹ç›¸å…³çš„é—®é¢˜ï¼Œå°½å¯èƒ½æä¾›è¯¦ç»†ã€å‡†ç¡®å’Œå®žç”¨çš„ç­”æ¡ˆï¼š\n",
    "    é—®é¢˜ï¼š{input}\n",
    "    ç­”æ¡ˆï¼š`\n",
    ")\n",
    "const generalPrompt = PromptTemplate.fromTemplate(\n",
    "    `è¯·å›žç­”ä»¥ä¸‹ä¸€èˆ¬æ€§é—®é¢˜ï¼Œå°½å¯èƒ½æä¾›å…¨é¢å’Œæœ‰æ·±åº¦çš„ç­”æ¡ˆï¼š\n",
    "    é—®é¢˜ï¼š{input}\n",
    "    ç­”æ¡ˆï¼š`\n",
    ")\n",
    "const scienceChain = RunnableSequence.from([\n",
    "    sciencePrompt,\n",
    "    answeringModel,\n",
    "    new StringOutputParser(),\n",
    "    {\n",
    "        output: input => input,\n",
    "        role: () => \"ç§‘æ™®ä¸“å®¶\"\n",
    "    }\n",
    "])\n",
    "\n",
    "const programmingChain = RunnableSequence.from([\n",
    "    programmingPrompt,\n",
    "    answeringModel,\n",
    "    new StringOutputParser(),\n",
    "    {\n",
    "        output: input => input,\n",
    "        role: () => \"ç¼–ç¨‹å¤§å¸ˆ\"\n",
    "    }\n",
    "])\n",
    "\n",
    "const generalChain = RunnableSequence.from([\n",
    "    generalPrompt,\n",
    "    answeringModel,\n",
    "    new StringOutputParser(),\n",
    "    {\n",
    "        output: input => input,\n",
    "        role: () => \"é€šè¯†ä¸“å®¶\"\n",
    "    }\n",
    "    \n",
    "])\n",
    "\n",
    "const branch = RunnableBranch.from([\n",
    "    [\n",
    "        (input => input.type.includes(\"ç§‘æ™®\")),\n",
    "        scienceChain,\n",
    "    ],\n",
    "    [\n",
    "        (input => input.type.includes(\"ç¼–ç¨‹\")),\n",
    "        programmingChain\n",
    "    ],\n",
    "    generalChain\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ„Ÿè°¢æ‚¨çš„æé—®ï¼Œè¿™æ˜¯æ¥è‡ªç§‘æ™®ä¸“å®¶çš„ä¸“ä¸šå›žç­”:\n",
      "    As a science communicator, I'd be happy to help clarify this question! ðŸ³ðŸ¦‡\n",
      "\n",
      "Answer: Yes, whales are mammals, and specifically, they belong to the order Cetacea. In fact, they are the largest group of mammals that live in the water.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "1. **Warm-bloodedness**: Like all mammals, whales are endothermic, meaning they generate heat internally to maintain a stable body temperature, regardless of their surroundings.\n",
      "2. **Breathing air**: Whales surface to breathe air through their blowholes (modified nostrils) and have lungs adapted for gas exchange. They don't use gills like fish do.\n",
      "3. **Mammary glands**: Female whales produce milk to feed their young, just like all other mammals. This is an essential characteristic that defines mammals.\n",
      "4. **Three middle ear bones**: Whales, like all mammals, have three middle ear bones (ossicles) that transmit sound vibrations to the inner ear.\n",
      "5. **Brain structure**: Whales possess a large brain-to-body mass ratio, which is typical of mammals.\n",
      "\n",
      "So, despite their aquatic lifestyle and massive size, whales are indeed mammals! ðŸ³ðŸ¦‡\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "const outputTemplate = PromptTemplate.fromTemplate(\n",
    "    `æ„Ÿè°¢æ‚¨çš„æé—®ï¼Œè¿™æ˜¯æ¥è‡ª{role}çš„ä¸“ä¸šå›žç­”:\n",
    "    {output}\n",
    "    `\n",
    ")\n",
    "\n",
    "const finalChain = RunnableSequence.from([\n",
    "    {\n",
    "        type: classifyChain,\n",
    "        input: input => input.input\n",
    "    },\n",
    "    branch,\n",
    "    (input) => outputTemplate.format(input)\n",
    "])\n",
    "const res = await finalChain.invoke({\n",
    "    \"input\": \"é²¸é±¼æ˜¯å“ºä¹³åŠ¨ç‰©ä¹ˆï¼Ÿ\"\n",
    "})\n",
    "\n",
    "console.log(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
